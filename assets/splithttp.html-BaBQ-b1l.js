import{_ as l,r as n,o as d,c as p,a as o,b as e,d as t,w as h,e as r}from"./app-DgchlZxK.js";const u={},b=e("h1",{id:"splithttp",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#splithttp"},[e("span",null,"SplitHTTP")])],-1),m=r(`<p>Uses HTTP chunked-transfer encoding for download, and multiple HTTP requests for upload.</p><p>Can be deployed on CDNs that do not support WebSocket. However, <strong>the CDN must support HTTP chunked transfer encoding in a streaming fashion</strong>, no response buffering.</p><p>This transport serves the same purpose as Meek (support non-WS CDN). It has the above streaming requirement to the CDN so that download can be much faster than (v2fly) Meek, close to WebSocket performance. The upload is also optimized, but still much more limited than WebSocket.</p><p>Like WebSocket transport, SplitHTTP parses the <code>X-Forwarded-For</code> header for logging.</p><h2 id="splithttpobject" tabindex="-1"><a class="header-anchor" href="#splithttpobject"><span>SplitHttpObject</span></a></h2><p>The <code>SplitHttpObject</code> corresponds to the <code>splithttpSettings</code> section under transport configurations.</p><div class="language-json line-numbers-mode" data-ext="json" data-title="json"><pre class="language-json"><code><span class="token punctuation">{</span>
  <span class="token property">&quot;path&quot;</span><span class="token operator">:</span> <span class="token string">&quot;/&quot;</span><span class="token punctuation">,</span>
  <span class="token property">&quot;host&quot;</span><span class="token operator">:</span> <span class="token string">&quot;xray.com&quot;</span><span class="token punctuation">,</span>
  <span class="token property">&quot;headers&quot;</span><span class="token operator">:</span> <span class="token punctuation">{</span>
    <span class="token property">&quot;key&quot;</span><span class="token operator">:</span> <span class="token string">&quot;value&quot;</span>
  <span class="token punctuation">}</span><span class="token punctuation">,</span>
  <span class="token property">&quot;scMaxEachPostBytes&quot;</span><span class="token operator">:</span> <span class="token number">1000000</span><span class="token punctuation">,</span>
  <span class="token property">&quot;scMaxConcurrentPosts&quot;</span><span class="token operator">:</span> <span class="token number">100</span><span class="token punctuation">,</span>
  <span class="token property">&quot;scMinPostsIntervalMs&quot;</span><span class="token operator">:</span> <span class="token number">30</span><span class="token punctuation">,</span>
  <span class="token property">&quot;noSSEHeader&quot;</span><span class="token operator">:</span> <span class="token boolean">false</span><span class="token punctuation">,</span>
  <span class="token property">&quot;xPaddingBytes&quot;</span><span class="token operator">:</span> <span class="token string">&quot;100-1000&quot;</span>
<span class="token punctuation">}</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><blockquote><p><code>path</code>: string</p></blockquote><p>HTTP path used by the connection. Defaults to <code>&quot;/&quot;</code>.</p><blockquote><p><code>host</code>: string</p></blockquote><p>HTTP Host sent by the connection. Empty by default. If this value is empty on the server, the host header sent by clients will not be validated.</p><p>If the <code>Host</code> header has been defined on the server in any way, the server will validate if the <code>Host</code> header matches.</p><p>The current priority of the <code>Host</code> header sent by clients: <code>host</code> &gt; <code>headers</code> &gt; <code>address</code></p><blockquote><p><code>headers</code>: map {string: string}</p></blockquote><p>Customized HTTP headers defined in key-value pairs. Defaults to empty.</p><blockquote><p><code>scMaxEachPostBytes</code>: int/string</p></blockquote><p>The maximum size of upload chunks, in bytes. Defaults to 1MB.</p><p>The size set by the client must be lower than this value, otherwise when the POST request is sent larger than the value set by the server, the request will be rejected.</p><p>This value should be smaller than the maximum request body allowed by the CDN or other HTTP reverse proxy, otherwise an HTTP 413 error will be thrown.</p><p>It can also be in the form of a string <code>&quot;1000000-2000000&quot;</code>. The core will randomly select a value within the range each time to reduce fingerprints.</p><blockquote><p><code>scMaxConcurrentPosts</code>: int/string</p></blockquote><p>The number of concurrent uploads to run. Defaults to 100 on the client, and 200 on the server.</p><p>The value on the client must not be higher than on the server. Otherwise, connectivity issues will occur. In practice, the upload concurrency is also limited by <code>minUploadIntervalMs</code>, so the actual concurrency on the client side will be much lower.</p><p>It can also be in the form of a string <code>&quot;100-200&quot;</code>, and the core will randomly select a value within the range each time to reduce fingerprints.</p><blockquote><p><code>scMinPostsIntervalMs</code>: int/string</p></blockquote><p>(Client-only) How much time to pass between upload requests at a minimum. Defaults to <code>30</code> (milliseconds).</p><p>It can also be in the form of a string <code>&quot;10-50&quot;</code>, and the core will randomly select a value within the range each time to reduce fingerprints.</p><blockquote><p><code>noSSEHeader</code></p></blockquote><p>(Server-only) Do not send the <code>Content-Type: text/event-stream</code> response header. Defaults to false (the header will be sent)</p><blockquote><p><code>xPaddingBytes</code></p></blockquote><p><em>Added in 1.8.24</em></p><p>Control the padding of requests and responses. Defaults to <code>&quot;100-1000&quot;</code>, meaning that each GET and POST will be padded with a random amount of bytes in that range.</p><p>A value of <code>-1</code> disables padding entirely.</p><p>You can lower this to save bandwidth or increase it to improve censorship resistance. Too much padding may cause the CDN to reject traffic.</p><h2 id="http-versions" tabindex="-1"><a class="header-anchor" href="#http-versions"><span>HTTP versions</span></a></h2><p><em>Added in 1.8.21: HTTP/3 support</em></p><p>SplitHTTP supports <code>http/1.1</code>, <code>h2</code> and <code>h3</code> ALPN values. If the value is not set, <code>h2</code> (prior-knowledge) is assumed when TLS is enabled, and <code>http/1.1</code> without TLS. If the value is set to <code>h3</code>, the client will attempt to connect as HTTP/3, so UDP instead of TCP.</p><p>The server listens to HTTP/1.1 and h2 by default, but if <code>h3</code> ALPN is set on the server, it will listen as HTTP/3.</p><p>Please note that nginx, Caddy and all CDN will almost certainly translate client requests to a different HTTP version for forwarding, and so the server may have to be configured with a different ALPN value than the client. If you use a CDN, it is very unlikely that <code>h3</code> is a correct value for the server, even if the client speaks <code>h3</code>.</p><h2 id="troubleshooting" tabindex="-1"><a class="header-anchor" href="#troubleshooting"><span>Troubleshooting</span></a></h2><ul><li><p>If a connection hangs, the CDN may not support streaming downloads. You can use <code>curl -Nv https://example.com/abcdef</code> to initiate a download and see for yourself (see protocol details).</p><p>If you do not see <code>200 OK</code> and a response body of <code>ok</code>, then the CDN is buffering the response body. Please ensure that all HTTP middleboxes along the path between client and server observe <code>X-Accel-Buffering: no</code> from their origin server. If your chain is <code>xray -&gt; nginx -&gt; CDN -&gt; xray</code>, nginx may strip this response header and you have to re-add it.</p></li></ul><h2 id="browser-dialer" tabindex="-1"><a class="header-anchor" href="#browser-dialer"><span>Browser Dialer</span></a></h2>`,42),f=e("h2",{id:"protocol-details",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#protocol-details"},[e("span",null,"Protocol details")])],-1),v={href:"https://github.com/XTLS/Xray-core/pull/3412",target:"_blank",rel:"noopener noreferrer"},y={href:"https://github.com/XTLS/Xray-core/pull/3462",target:"_blank",rel:"noopener noreferrer"},g=r("<ol><li><p><code>GET /&lt;UUID&gt;</code> opens the download. The server immediately responds with <code>200 OK</code>, and immediately sends the string <code>ok</code> (arbitrary length, such as <code>ooook</code>) to force HTTP middleboxes into flushing headers.</p><p>The server will send these headers:</p><ul><li><code>X-Accel-Buffering: no</code> to prevent response buffering in nginx and CDN</li><li><code>Content-Type: text/event-stream</code> to prevent response buffering in some CDN, can be disabled with <code>noSSEHeader</code></li><li><code>Transfer-Encoding: chunked</code> in HTTP/1.1 only</li><li><code>Cache-Control: no-store</code> to disable any potential response caching.</li></ul></li><li><p>Client uploads using <code>POST /&lt;UUID&gt;/&lt;seq&gt;</code>. <code>seq</code> starts at <code>0</code> and can be used like TCP seq number, and multiple &quot;packets&quot; may be sent concurrently. The server has to reassemble the &quot;packets&quot; live. The sequence number never resets for simplicity reasons.</p><p>The client may open upload and download in any order, either one starts a session. However, eventually <code>GET</code> needs to be opened (current deadline is hardcoded to 30 seconds) If not, the session will be terminated.</p></li><li><p>The <code>GET</code> request is kept open until the tunneled connection has to be terminated. Either server or client can close.</p><p>How this actually works depends on the HTTP version. For example, in HTTP/1.1 it is only possible to disrupt chunked-transfer by closing the TCP connection, in other versions the stream is closed or aborted.</p></li></ol><p>Recommendations:</p><ul><li><p>Do not assume any custom headers are transferred correctly by the CDN. This transport is built for CDN who do not support WebSocket, these CDN tend to not be very modern (or good).</p></li><li><p>It should be assumed there is no streaming upload within a HTTP request, so the size of a packet should be chosen to optimize between latency, throughput, and any size limits imposed by the CDN (just like TCP, nagle&#39;s algorithm and MTU...)</p></li><li><p>HTTP/1.1 and h2 should be supported by server and client, and it should be expected that the CDN will translate arbitrarily between versions. A HTTP/1.1 server may indirectly end up talking to a h2 client, and vice versa.</p></li></ul>",3);function T(k,q){const i=n("I18nTip"),s=n("Badge"),c=n("RouterLink"),a=n("ExternalLinkIcon");return d(),p("div",null,[o(i),b,o(s,{text:"v1.8.16+",type:"warning"}),m,o(s,{text:"v1.8.17+",type:"warning"}),e("p",null,[t("If uTLS is not enough, SplitHTTP's TLS can be handled by a browser using "),o(c,{to:"/en/config/features/browser_dialer.html"},{default:h(()=>[t("Browser Dialer")]),_:1})]),f,e("p",null,[t("See "),e("a",v,[t("#3412"),o(a)]),t(" and "),e("a",y,[t("#3462"),o(a)]),t(" for extensive discussion and revision of the protocol. Here is a summary, and the minimum needed to be compatible:")]),g])}const P=l(u,[["render",T],["__file","splithttp.html.vue"]]);export{P as default};
